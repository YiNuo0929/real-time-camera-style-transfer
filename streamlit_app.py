import streamlit as st
import onnxruntime as ort
import numpy as np
import cv2
import time
from io import BytesIO
from PIL import Image

# Streamlit é é¢è¨­å®š
st.set_page_config(page_title="ğŸ¨ Real-time Style Transfer (ONNX)", layout="wide")
st.title("ğŸ¥ Real-time Neural Style Transfer - ONNXRuntime GPU è‡ªå‹•åˆ‡æ›ç‰ˆ")
st.markdown("Upload style images and activate your webcam to apply artistic style in real time!")

# âœ… å˜—è©¦å»ºç«‹ GPU Sessionï¼Œè‹¥å¤±æ•—å‰‡ fallback åˆ° CPU
@st.cache_resource
def load_onnx_model():
    try:
        session = ort.InferenceSession("stylization.onnx", providers=[
            "TensorrtExecutionProvider",
            "CUDAExecutionProvider",
            "CPUExecutionProvider"
        ])
    except Exception as e:
        st.warning(f"âš ï¸ GPU/TensorRT unavailable, fallback to CPU. Error: {e}")
        session = ort.InferenceSession("stylization.onnx", providers=["CPUExecutionProvider"])
    return session

# ä¸Šå‚³é¢¨æ ¼åœ–åƒï¼ˆå¯ä»¥å¤šå¼µï¼‰
style_image_files = st.file_uploader(
    "Upload Style Images", type=["jpg", "jpeg", "png"], accept_multiple_files=True
)

if style_image_files:
    style_images = []
    style_names = []
    for uploaded_file in style_image_files:
        image_data = uploaded_file.read()
        image = Image.open(BytesIO(image_data)).convert('RGB')
        image = np.array(image).astype(np.float32)[np.newaxis, ...] / 255.
        image = cv2.resize(image[0], (256, 256))
        image = image[np.newaxis, ...].astype(np.float32)
        style_images.append(image)
        style_names.append(uploaded_file.name)

    st.success(f"âœ… è¼‰å…¥ {len(style_images)} å¼µé¢¨æ ¼åœ–ï¼")

    # è¼‰å…¥ ONNX æ¨¡å‹
    with st.spinner("Loading ONNX model..."):
        session = load_onnx_model()
        input_names = [i.name for i in session.get_inputs()]
        backend = session.get_providers()[0]
        st.success("âœ… ONNX æ¨¡å‹å·²æˆåŠŸè¼‰å…¥ï¼")
        st.markdown(f"ğŸ“¥ **æ¨¡å‹è¼¸å…¥åç¨±ï¼š** `{input_names}`")
        st.markdown(f"ğŸ§  **ä½¿ç”¨ä¸­çš„æ¨è«–å¾Œç«¯ï¼š** `{backend}`")

    # ç‹€æ…‹è®Šæ•¸
    if 'style_index' not in st.session_state:
        st.session_state.style_index = 0
    if 'running' not in st.session_state:
        st.session_state.running = False

    # åˆ‡æ›æŒ‰éˆ•
    if st.button("Next Style"):
        st.session_state.style_index = (st.session_state.style_index + 1) % len(style_images)

    # é¡¯ç¤ºç•¶å‰é¢¨æ ¼ç·¨è™Ÿ
    st.markdown(f"ğŸ¨ **ç›®å‰é¢¨æ ¼ï¼šç¬¬ {st.session_state.style_index + 1} å¼µ ({style_names[st.session_state.style_index]})**")

    # å•Ÿå‹•æŒ‰éˆ•
    if not st.session_state.running:
        if st.button("ğŸ¬ Start Stylization"):
            st.session_state.running = True

    if st.session_state.running:
        video_capture = cv2.VideoCapture(0)
        if not video_capture.isOpened():
            st.error("âŒ Cannot access webcam.")
        else:
            frame_display = st.empty()
            fps_display = st.empty()
            st.info("ğŸš¨ Close Streamlit tab to end.")

            prev_time = time.time()
            frame_count = 0

            while True:
                ret, frame = video_capture.read()
                if not ret:
                    break

                frame_count += 1

                # FPS è¨ˆç®—
                current_time = time.time()
                elapsed = current_time - prev_time
                if elapsed >= 1.0:
                    fps = frame_count / elapsed
                    fps_display.markdown(f"### ğŸŒ€ FPS: `{fps:.2f}`")
                    frame_count = 0
                    prev_time = current_time

                # é è™•ç†å…§å®¹åœ–åƒ
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                content_tensor = cv2.resize(frame_rgb, (256, 256))
                content_tensor = content_tensor.astype(np.float32)[np.newaxis, ...] / 255.

                # ONNX æ¨è«–ï¼ˆæ ¹æ“šç›®å‰çš„ style_indexï¼‰
                result = session.run(None, {
                    input_names[0]: content_tensor,
                    input_names[1]: style_images[st.session_state.style_index]
                })

                stylized_frame = (result[0][0] * 255).astype(np.uint8)
                frame_display.image(stylized_frame, channels="RGB", width=512)

            video_capture.release()