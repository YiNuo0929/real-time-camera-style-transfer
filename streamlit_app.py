import streamlit as st
import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import cv2
import time
from io import BytesIO
from PIL import Image

# Streamlit é é¢è¨­å®š
st.set_page_config(page_title="ğŸ¨ Real-time Style Transfer", layout="wide")
st.title("ğŸ¥ Real-time Neural Style Transfer")
st.markdown("Upload a style image and activate your webcam to apply artistic style in real time!")

# âœ… å¿«å–æœ¬åœ°æ¨¡å‹ï¼ˆéœ€è¦ Streamlit v1.18+ï¼‰
@st.cache_resource
def load_style_model():
    return hub.load('./style_model')  # æœ¬åœ°æ¨¡å‹è³‡æ–™å¤¾

# ä¸Šå‚³é¢¨æ ¼åœ–ç‰‡
style_image_file = st.file_uploader("Upload Style Image", type=["jpg", "jpeg", "png"])

# ç•¶ä½¿ç”¨è€…ä¸Šå‚³é¢¨æ ¼åœ–å¾Œ
if style_image_file:
    # è™•ç† style image
    image_data = style_image_file.read()
    image = Image.open(BytesIO(image_data)).convert('RGB')
    style_image = np.array(image).astype(np.float32)[np.newaxis, ...] / 255.
    style_image = tf.image.resize(style_image, [256, 256])

    # è¼‰å…¥æœ¬åœ°æ¨¡å‹
    with st.spinner("Loading style transfer model..."):
        hub_module = load_style_model()
        st.success("âœ… æ¨¡å‹å·²å¾æœ¬åœ°æˆåŠŸè¼‰å…¥ï¼")

    # å•Ÿå‹•å³æ™‚é¢¨æ ¼è½‰æ›æŒ‰éˆ•
    if st.button("ğŸ¬ Start Stylization"):
        video_capture = cv2.VideoCapture(0)
        if not video_capture.isOpened():
            st.error("âŒ Cannot access webcam. Please make sure it's connected and not in use.")
        else:
            frame_display = st.empty()  # Streamlit é¡¯ç¤ºå€åŸŸ
            st.info("ğŸš¨ Press the 'Stop' button (top-right corner) or close the app window to end.")

            fps_display = st.empty()  # å»ºç«‹ä¸€å€‹å¯æ›´æ–°å€å¡Š
            prev_time = time.time()
            frame_count = 0
            while video_capture.isOpened():
                ret, frame = video_capture.read()
                if not ret:
                    break

                frame_count += 1

                # è™•ç†èˆ‡é¢¨æ ¼è½‰æ›...
                # frame_display.image(...)

                # æ¯ç§’æ›´æ–°ä¸€æ¬¡ FPS é¡¯ç¤º
                current_time = time.time()
                elapsed = current_time - prev_time
                if elapsed >= 1.0:
                    fps = frame_count / elapsed
                    fps_display.markdown(f"### ğŸŒ€ FPS: `{fps:.2f}`")  # é¡¯ç¤ºåœ¨ç¶²é ä¸Š
                    frame_count = 0
                    prev_time = current_time

                # é è™•ç†æ¯ä¸€å¹€ç•«é¢
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frame_tensor = tf.image.resize(frame_rgb.astype(np.float32)[np.newaxis, ...] / 255., [256, 256])

                # åŸ·è¡Œé¢¨æ ¼è½‰æ›
                stylized_output = hub_module(tf.constant(frame_tensor), tf.constant(style_image, dtype=tf.float32))
                stylized_frame = stylized_output[0].numpy()[0]
                stylized_frame = (stylized_frame * 255).astype(np.uint8)

                # é¡¯ç¤ºç•«é¢
                frame_display.image(stylized_frame, channels="RGB", width=512)

                #time.sleep(0.05)  # å¯é¸å»¶é²æ¨¡æ“¬å³æ™‚æ„Ÿ

            video_capture.release()